import streamlit as st
import cv2
import numpy as np
from PIL import Image

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é¢—ç²’ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ¾",
    layout="wide"
)

def detect_defective_grains(image):
    """æ ¸å¿ƒæ£€æµ‹é€»è¾‘"""
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # é«˜æ–¯æ¨¡ç³Šé™å™ª
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)
    
    # è‡ªé€‚åº”é˜ˆå€¼å¤„ç†
    thresh = cv2.adaptiveThreshold(
        blurred, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # å½¢æ€å­¦æ“ä½œ
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(
        cleaned, 
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )
    
    # ç­›é€‰æœ‰æ•ˆè½®å»“ï¼ˆé¢ç§¯å¤§äº50åƒç´ ï¼‰
    valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 50]
    
    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    result_img = image.copy()
    cv2.drawContours(result_img, valid_contours, -1, (0,255,0), 2)
    
    return result_img, len(valid_contours), gray, thresh

def advanced_processing(image):
    # HSVé¢œè‰²ç©ºé—´åˆ†æ
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    
    # è®¾ç½®é¢œè‰²é˜ˆå€¼ï¼ˆéœ€å®é™…è°ƒæ•´ï¼‰
    lower = np.array([15, 50, 50])
    upper = np.array([35, 255, 255])
    
    # åˆ›å»ºé¢œè‰²æ©æ¨¡
    mask = cv2.inRange(hsv, lower, upper)
    
    # ç»“åˆå½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))
    refined_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    return refined_mask
def advanced_preprocessing(img):
    # åŒæ€æ»¤æ³¢æ¶ˆé™¤å…‰ç…§å½±å“
    img_YUV = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
    Y = img_YUV[:,:,0].astype(float)/255
    
    # é«˜æ–¯æ»¤æ³¢æ ¸
    rows, cols = Y.shape
    sigma = 30
    X, Y = np.meshgrid(np.linspace(0,cols-1,cols), np.linspace(0,rows-1,rows))
    gaussian_kernel = np.exp(-((X - cols/2)**2 + (Y - rows/2)**2)/(2*sigma**2))
    
    # é¢‘åŸŸå¤„ç†
    Y_fft = np.fft.fft2(Y)
    Y_fft_shift = np.fft.fftshift(Y_fft)
    Y_filtered = Y_fft_shift * (1 + 0.5*gaussian_kernel)  # é«˜é¢‘å¢å¼º
    
    # é€†å˜æ¢
    Y_reconstructed = np.abs(np.fft.ifft2(np.fft.ifftshift(Y_filtered)))
    img_YUV[:,:,0] = np.uint8(np.clip(Y_reconstructed*255, 0, 255))
    return cv2.cvtColor(img_YUV, cv2.COLOR_YUV2BGR)

def multi_scale_segmentation(img):
    # æ„å»ºé«˜æ–¯é‡‘å­—å¡”
    pyramid = [cv2.pyrDown(img)]
    for _ in range(2):
        pyramid.append(cv2.pyrDown(pyramid[-1]))
    
    # å¤šå°ºåº¦æ£€æµ‹
    all_contours = []
    for level, layer in enumerate(pyramid):
        gray = cv2.cvtColor(layer, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50*level, 150*level)
        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        # åæ ‡æ˜ å°„å›åŸå›¾å°ºå¯¸
        scale_factor = 2 ** (level + 1)
        scaled_contours = [cnt * scale_factor for cnt in contours]
        all_contours.extend(scaled_contours)
    
    return all_contours
import torch
from torchvision import transforms

class DefectDetector:
    def __init__(self):
        self.classifier = torch.load('defect_classifier.pth')
        self.segmentor = torch.load('segmentation_unet.pth')
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    
    def detect(self, img):
        # ç¬¬ä¸€é˜¶æ®µï¼šç²—æ£€æµ‹
        tensor_img = self.transform(Image.fromarray(img))
        with torch.no_grad():
            pred = self.classifier(tensor_img.unsqueeze(0))
        
        if pred[0][1] < 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
            return []
        
        # ç¬¬äºŒé˜¶æ®µï¼šç²¾ç»†åˆ†å‰²
        mask = self.segmentor(tensor_img.unsqueeze(0))
        return self.postprocess_mask(mask)

# ç½‘é¡µç•Œé¢
st.title("ğŸŒ¾ ç³™ç±³ä¸å®Œå–„ç²’æ£€æµ‹ç³»ç»Ÿ")
st.markdown("---")

# ä¾§è¾¹æ å‚æ•°è®¾ç½®
with st.sidebar:
    st.header("æ£€æµ‹å‚æ•°è®¾ç½®")
    min_area = st.slider("æœ€å°é¢—ç²’é¢ç§¯", 10, 200, 50)
    blur_size = st.slider("é™å™ªå¼ºåº¦", 3, 15, 9, step=2)
    threshold_type = st.selectbox("é˜ˆå€¼æ–¹æ³•", ["è‡ªé€‚åº”é˜ˆå€¼", "å…¨å±€é˜ˆå€¼"])

# æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
uploaded_file = st.file_uploader(
    "ä¸Šä¼ å¾…æ£€æµ‹å›¾ç‰‡ï¼ˆæ”¯æŒJPG/PNGï¼‰",
    type=["jpg", "png", "jpeg"]
)

if uploaded_file is not None:
    # è½¬æ¢ä¸Šä¼ æ–‡ä»¶ä¸ºOpenCVæ ¼å¼
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    
    with st.spinner("æ­£åœ¨åˆ†æä¸­..."):
        # æ‰§è¡Œæ£€æµ‹
        result_img, defect_count, gray, thresh = detect_defective_grains(image)
        
        # æ˜¾ç¤ºç»“æœ
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="åŸå§‹å›¾åƒ", use_container_width=True, channels="BGR")
        with col2:
            st.image(result_img, caption="æ£€æµ‹ç»“æœ", use_container_width=True, channels="BGR")
    with st.expander("æŸ¥çœ‹ä¸­é—´å¤„ç†è¿‡ç¨‹"):
        tab1, tab2, tab3 = st.tabs(["ç°åº¦å›¾", "äºŒå€¼åŒ–", "é¢œè‰²åˆ†æ"])
        
        with tab1:
            st.image(gray, caption="ç°åº¦å¤„ç†", use_column_width=True)
        with tab2:
            st.image(thresh, caption="äºŒå€¼åŒ–ç»“æœ", use_column_width=True)
        with tab3:
            refined_mask = advanced_processing(image)
            st.image(refined_mask, caption="é¢œè‰²åˆ†æ", use_column_width=True)
       
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        st.success(f"æ£€æµ‹å®Œæˆï¼å‘ç°ç–‘ä¼¼ç¼ºé™·é¢—ç²’ï¼š{defect_count}å¤„")
        st.metric("ç¼ºé™·é¢—ç²’æ•°é‡", defect_count)
        
        # æ·»åŠ ä¸‹è½½æŒ‰é’®
        result_pil = Image.fromarray(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))
        st.download_button(
            label="ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
            data=result_pil.tobytes(),
            file_name="æ£€æµ‹ç»“æœ.png",
            mime="image/png"
        )

else:
    st.info("è¯·ä¸Šä¼ éœ€è¦æ£€æµ‹çš„å›¾ç‰‡æ–‡ä»¶")

st.markdown("---")
st.caption("Developed by LSQ| æ£€æµ‹ç®—æ³•ç‰ˆæœ¬2.0")
